<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>reveal.js</title>

		<link rel="stylesheet" href="css/reset.css">
		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/moon.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/monokai.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
        <section>
          <h2> Overview of audio synthesis using deep learning </h2>
          <ul>
            <li> Reference: "Generating music in the waveform domain", by
              Sander Dieleman </li>
            <li> https://benanne.github.io/2020/03/24/audio-generation.html </li>
          </ul>
        <section>
          <h2> Why audio? </h2>
          <ul>
            <li> models that take symbolic input and outputs a waveform </li>
          </ul>
        </section>

        <section>
          <h2> Why audio?</h2>
          <img src="https://benanne.github.io/images/player_piano.jpg">
        </section>
        <section>
          <h2> Why audio? </h2>
          <img src="https://benanne.github.io/images/piano_roll.jpg">
        </section>

        <section>
          <h2> Why waveforms? </h2>
          <img src="https://benanne.github.io/images/spectrogram_magnitude.png">
          <img src="https://benanne.github.io/images/spectrogram_phase.png">
        </section>

        <section>
          <h2> What is audio? </h2>
          <ul>
            <li> continuous local variations in pressure </li>
          </ul>
        </section>

        <section>
          <h2> What is digital audio? </h2>
          <ul>
            <li> discrete measurements of variations in pressure </li>
          </ul>
        </section>

        <section>
          <h2> Challenges for machine learning? </h2>
          <ul>
            <li> </li>
          </ul>
        </section>

        <section>
          <h2> Traditional audio synthesis </h2>
          <ul>
            <li> speech synthesis: text to speech </li>
            <li> music synthesis: MIDI to music </li>
            <li> symbolic representations </li>
          </ul>
        </section>



				<section>
					<p class ="fragment" data-audio-src="audio/melgan.ogg">
						Listen to melgan
					</p>
				</section>
			</div>
		</div>

		<script src="js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
		Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,
				mouseWheel: true,
				audio: {
					prefix: 'audio-slideshow/',
					suffix: '.ogg',
					defaultDuration: 5,
					textToSpeechURL: "http://api.voicerss.org/?key=[YOUR_KEY]&hl=en-gb&c=ogg&src=",
					advance: 500,
					autoplay: false,
					defaultNotes: true,
					defaultText: false,
					playerOpacity: 0.2,
				},
				menu: { // Menu works best with font-awesome installed: sudo apt-get install fonts-font-awesome
					themes: false,
					transitions: false,
					markers: true,
					hideMissingTitles: true,
					custom: [
				            { title: 'Plugins', icon: '<i class="fa fa-external-link-alt"></i>', src: 'toc.html' },
				            { title: 'About', icon: '<i class="fa fa-info"></i>', src: 'about.html' }
				        ]
				},
				theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
				transition: Reveal.getQueryHash().transition || 'none', // none/fade/slide/convex/concave/zoom

				// Optional libraries used to extend on reveal.js
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/audio-slideshow/RecordRTC.js', condition: function( ) { return !!document.body.classList; } },				
					{ src: 'plugin/audio-slideshow/slideshow-recorder.js', condition: function( ) { return !!document.body.classList; } },				
					{ src: 'plugin/audio-slideshow/audio-slideshow.js', condition: function( ) { return !!document.body.classList; } },
					{ src: 'plugin/menu/menu.js' },
				],
				keyboard: { 
					82: function() { Recorder.toggleRecording(); },	// press 'r' to start/stop recording
					90: function() { Recorder.downloadZip(); }, 	// press 'z' to download zip containing audio files
					84: function() { Recorder.fetchTTS(); } 	// press 't' to fetch TTS audio files
  				}
			});
		</script>
	</body>
</html>
